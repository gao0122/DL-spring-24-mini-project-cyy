Namespace(n=3, batch=128, dataset_dir='./dataset', checkpoint_dir='ckpt', print_freq=10, save_params_freq=1000, lr=0.0003, weight_decay=0.0005, decay_lr_1=24000, decay_lr_2=42000, lr_decay_rate=0.1, n_iter=48000)
Files already downloaded and verified
Total number of parameters : 0.270 M
iter:     10, loss: 3.4015734672546385
iter:     10, loss: 3.4015734672546385
iter:     20, loss: 2.636850428581238
iter:     20, loss: 2.636850428581238
iter:     30, loss: 2.2936164855957033
iter:     30, loss: 2.2936164855957033
iter:     40, loss: 2.1759725213050842
iter:     40, loss: 2.1759725213050842
iter:     50, loss: 2.016197383403778
iter:     50, loss: 2.016197383403778
iter:     60, loss: 1.9595953106880188
iter:     60, loss: 1.9595953106880188
iter:     70, loss: 1.8716244220733642
iter:     70, loss: 1.8716244220733642
iter:     80, loss: 1.8495353221893311
iter:     80, loss: 1.8495353221893311
iter:     90, loss: 1.7611601233482361
iter:     90, loss: 1.7611601233482361
iter:    100, loss: 1.736927616596222
iter:    100, loss: 1.736927616596222
iter:    110, loss: 1.7079331040382386
iter:    110, loss: 1.7079331040382386
iter:    120, loss: 1.65033917427063
iter:    120, loss: 1.65033917427063
iter:    130, loss: 1.711760413646698
iter:    130, loss: 1.711760413646698
iter:    140, loss: 1.7085509538650512
iter:    140, loss: 1.7085509538650512
iter:    150, loss: 1.6674277067184449
iter:    150, loss: 1.6674277067184449
iter:    160, loss: 1.650610089302063
iter:    160, loss: 1.650610089302063
iter:    170, loss: 1.6367905735969543
iter:    170, loss: 1.6367905735969543
iter:    180, loss: 1.6482176184654236
iter:    180, loss: 1.6482176184654236
iter:    190, loss: 1.6507140278816224
iter:    190, loss: 1.6507140278816224
iter:    200, loss: 1.5868719100952149
iter:    200, loss: 1.5868719100952149
iter:    210, loss: 1.5536062836647033
iter:    210, loss: 1.5536062836647033
iter:    220, loss: 1.5686545372009277
iter:    220, loss: 1.5686545372009277
iter:    230, loss: 1.5132515549659729
iter:    230, loss: 1.5132515549659729
iter:    240, loss: 1.5452116966247558
iter:    240, loss: 1.5452116966247558
iter:    250, loss: 1.5613711833953858
iter:    250, loss: 1.5613711833953858
iter:    260, loss: 1.5276501655578614
iter:    260, loss: 1.5276501655578614
iter:    270, loss: 1.5266482472419738
iter:    270, loss: 1.5266482472419738
iter:    280, loss: 1.5007749915122985
iter:    280, loss: 1.5007749915122985
iter:    290, loss: 1.5304522156715392
iter:    290, loss: 1.5304522156715392
iter:    300, loss: 1.4580971717834472
iter:    300, loss: 1.4580971717834472
iter:    310, loss: 1.485313093662262
iter:    310, loss: 1.485313093662262
iter:    320, loss: 1.5084266424179078
iter:    320, loss: 1.5084266424179078
iter:    330, loss: 1.418742024898529
iter:    330, loss: 1.418742024898529
iter:    340, loss: 1.4324540376663208
iter:    340, loss: 1.4324540376663208
iter:    350, loss: 1.4943490028381348
iter:    350, loss: 1.4943490028381348
iter:    360, loss: 1.4086941480636597
iter:    360, loss: 1.4086941480636597
iter:    370, loss: 1.4435554027557373
iter:    370, loss: 1.4435554027557373
iter:    380, loss: 1.4396993041038513
iter:    380, loss: 1.4396993041038513
iter:    390, loss: 1.3931663155555725
iter:    390, loss: 1.3931663155555725
iter:    400, loss: 1.442468535900116
iter:    400, loss: 1.442468535900116
iter:    410, loss: 1.363092827796936
iter:    410, loss: 1.363092827796936
iter:    420, loss: 1.3841580271720886
iter:    420, loss: 1.3841580271720886
iter:    430, loss: 1.3758810043334961
iter:    430, loss: 1.3758810043334961
iter:    440, loss: 1.403476929664612
iter:    440, loss: 1.403476929664612
iter:    450, loss: 1.4033646702766418
iter:    450, loss: 1.4033646702766418
iter:    460, loss: 1.4077894926071166
iter:    460, loss: 1.4077894926071166
iter:    470, loss: 1.3789000868797303
iter:    470, loss: 1.3789000868797303
iter:    480, loss: 1.3431918263435363
iter:    480, loss: 1.3431918263435363
iter:    490, loss: 1.3968944549560547
iter:    490, loss: 1.3968944549560547
iter:    500, loss: 1.3631042003631593
iter:    500, loss: 1.3631042003631593
iter:    510, loss: 1.3451784372329711
iter:    510, loss: 1.3451784372329711
iter:    520, loss: 1.334065020084381
iter:    520, loss: 1.334065020084381
iter:    530, loss: 1.2981509208679198
iter:    530, loss: 1.2981509208679198
iter:    540, loss: 1.3100277304649353
iter:    540, loss: 1.3100277304649353
iter:    550, loss: 1.3789497375488282
iter:    550, loss: 1.3789497375488282
iter:    560, loss: 1.3507867217063905
iter:    560, loss: 1.3507867217063905
iter:    570, loss: 1.312687587738037
iter:    570, loss: 1.312687587738037
iter:    580, loss: 1.3386009216308594
iter:    580, loss: 1.3386009216308594
iter:    590, loss: 1.3399754524230958
iter:    590, loss: 1.3399754524230958
iter:    600, loss: 1.3450465202331543
iter:    600, loss: 1.3450465202331543
iter:    610, loss: 1.3151829600334168
iter:    610, loss: 1.3151829600334168
iter:    620, loss: 1.3256276845932007
iter:    620, loss: 1.3256276845932007
iter:    630, loss: 1.2880055785179139
iter:    630, loss: 1.2880055785179139
iter:    640, loss: 1.260023546218872
iter:    640, loss: 1.260023546218872
iter:    650, loss: 1.3331434369087218
iter:    650, loss: 1.3331434369087218
iter:    660, loss: 1.3083191633224487
iter:    660, loss: 1.3083191633224487
iter:    670, loss: 1.2698510408401489
iter:    670, loss: 1.2698510408401489
iter:    680, loss: 1.2175089359283446
iter:    680, loss: 1.2175089359283446
iter:    690, loss: 1.2851445198059082
iter:    690, loss: 1.2851445198059082
iter:    700, loss: 1.253565776348114
iter:    700, loss: 1.253565776348114
iter:    710, loss: 1.2577079653739929
iter:    710, loss: 1.2577079653739929
iter:    720, loss: 1.2417821288108826
iter:    720, loss: 1.2417821288108826
iter:    730, loss: 1.262176513671875
iter:    730, loss: 1.262176513671875
iter:    740, loss: 1.2759334564208984
iter:    740, loss: 1.2759334564208984
iter:    750, loss: 1.2854106903076172
iter:    750, loss: 1.2854106903076172
iter:    760, loss: 1.2701359868049622
iter:    760, loss: 1.2701359868049622
iter:    770, loss: 1.2048105120658874
iter:    770, loss: 1.2048105120658874
iter:    780, loss: 1.2223661541938782
iter:    780, loss: 1.2223661541938782
iter:    790, loss: 1.2006717324256897
iter:    790, loss: 1.2006717324256897
iter:    800, loss: 1.1911672353744507
iter:    800, loss: 1.1911672353744507
iter:    810, loss: 1.2172113537788392
iter:    810, loss: 1.2172113537788392
iter:    820, loss: 1.2104694604873658
iter:    820, loss: 1.2104694604873658
iter:    830, loss: 1.2239310264587402
iter:    830, loss: 1.2239310264587402
iter:    840, loss: 1.1956772565841676
iter:    840, loss: 1.1956772565841676
iter:    850, loss: 1.1844629526138306
iter:    850, loss: 1.1844629526138306
iter:    860, loss: 1.1756988644599915
iter:    860, loss: 1.1756988644599915
iter:    870, loss: 1.2230476498603822
iter:    870, loss: 1.2230476498603822
iter:    880, loss: 1.1653383135795594
iter:    880, loss: 1.1653383135795594
iter:    890, loss: 1.2394620895385742
iter:    890, loss: 1.2394620895385742
iter:    900, loss: 1.1826215147972108
iter:    900, loss: 1.1826215147972108
iter:    910, loss: 1.159947431087494
iter:    910, loss: 1.159947431087494
iter:    920, loss: 1.2047431945800782
iter:    920, loss: 1.2047431945800782
iter:    930, loss: 1.1652162671089172
iter:    930, loss: 1.1652162671089172
iter:    940, loss: 1.124900460243225
iter:    940, loss: 1.124900460243225
iter:    950, loss: 1.1808230996131897
iter:    950, loss: 1.1808230996131897
iter:    960, loss: 1.194135344028473
iter:    960, loss: 1.194135344028473
iter:    970, loss: 1.2087666869163514
iter:    970, loss: 1.2087666869163514
iter:    980, loss: 1.1857993602752686
iter:    980, loss: 1.1857993602752686
iter:    990, loss: 1.1639990329742431
iter:    990, loss: 1.1639990329742431
iter:   1000, loss: 1.1666044473648072
iter:   1000, loss: 1.1666044473648072
Traceback (most recent call last):
  File "/home/yc6785/project/resnet-cifar10-master/train.py", line 49, in <module>
    train(args)
  File "/home/yc6785/project/resnet-cifar10-master/train.py", line 39, in train
    model.save_model(f'{total_iter // opt.save_params_freq}k')
  File "/home/yc6785/project/resnet-cifar10-master/models.py", line 104, in save_model
    path = os.path.join(self.checkpoint_dir, f'model_{name}.pth')
                        ^^^^^^^^^^^^^^^^^^^
AttributeError: 'ResNetModel' object has no attribute 'checkpoint_dir'
Namespace(n=3, batch=128, dataset_dir='./dataset', params_path='ckpt/model_final.pth', is_kaggle=0)
Total number of parameters : 0.270 M
model loaded from ckpt/model_final.pth
Files already downloaded and verified
accuracy: 92.15 %
error: 7.85 %
9215 / 10000
Namespace(n=3, batch=128, dataset_dir='./dataset', params_path='ckpt/model_final.pth', is_kaggle=1)
Total number of parameters : 0.270 M
model loaded from ckpt/model_final.pth
kaggle done
